{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "41b38629-be39-4b15-a890-57907dbded83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8741e2e6-5b16-4aec-a994-e1945aa97502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.523992</td>\n",
       "      <td>0.407881</td>\n",
       "      <td>0.139516</td>\n",
       "      <td>0.828742</td>\n",
       "      <td>0.359367</td>\n",
       "      <td>0.180594</td>\n",
       "      <td>0.238831</td>\n",
       "      <td>9.933684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.120093</td>\n",
       "      <td>0.099240</td>\n",
       "      <td>0.041827</td>\n",
       "      <td>0.490389</td>\n",
       "      <td>0.221963</td>\n",
       "      <td>0.109614</td>\n",
       "      <td>0.139203</td>\n",
       "      <td>3.224169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.799500</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>1.153000</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.329000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>2.825500</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Length     Diameter       Height  Whole weight  Shucked weight  \\\n",
       "count  4177.000000  4177.000000  4177.000000   4177.000000     4177.000000   \n",
       "mean      0.523992     0.407881     0.139516      0.828742        0.359367   \n",
       "std       0.120093     0.099240     0.041827      0.490389        0.221963   \n",
       "min       0.075000     0.055000     0.000000      0.002000        0.001000   \n",
       "25%       0.450000     0.350000     0.115000      0.441500        0.186000   \n",
       "50%       0.545000     0.425000     0.140000      0.799500        0.336000   \n",
       "75%       0.615000     0.480000     0.165000      1.153000        0.502000   \n",
       "max       0.815000     0.650000     1.130000      2.825500        1.488000   \n",
       "\n",
       "       Viscera weight  Shell weight        Rings  \n",
       "count     4177.000000   4177.000000  4177.000000  \n",
       "mean         0.180594      0.238831     9.933684  \n",
       "std          0.109614      0.139203     3.224169  \n",
       "min          0.000500      0.001500     1.000000  \n",
       "25%          0.093500      0.130000     8.000000  \n",
       "50%          0.171000      0.234000     9.000000  \n",
       "75%          0.253000      0.329000    11.000000  \n",
       "max          0.760000      1.005000    29.000000  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abalone = pd.read_csv(\"데이터셋/abalone.csv\")\n",
    "df_abalone.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4e5c07ae-e62a-4ff8-8ded-d4e1896746de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4177 entries, 0 to 4176\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Sex             4177 non-null   object \n",
      " 1   Length          4177 non-null   float64\n",
      " 2   Diameter        4177 non-null   float64\n",
      " 3   Height          4177 non-null   float64\n",
      " 4   Whole weight    4177 non-null   float64\n",
      " 5   Shucked weight  4177 non-null   float64\n",
      " 6   Viscera weight  4177 non-null   float64\n",
      " 7   Shell weight    4177 non-null   float64\n",
      " 8   Rings           4177 non-null   int64  \n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 293.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_abalone.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6bbbcbfc-886e-420e-bbdd-ef2d5d6f183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_excute(epoch_count = 10, mb_size = 2, report = 2, train_ratio = 0.8):\n",
    "    load_dataset()\n",
    "    weight_initial, bias_initial = init_param()\n",
    "    losses_mean_row, accs_mean_row, final_acc = train_and_test(epoch_count,mb_size, report, train_ratio)\n",
    "    \n",
    "    return weight_initial, bias_initial, losses_mean_row, accs_mean_row, final_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c0ac6419-5e77-42e5-beb6-4bbf1da3adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    with open('데이터셋/abalone.csv') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader)\n",
    "        rows = []\n",
    "        for row in csvreader:\n",
    "            rows.append(row)\n",
    "\n",
    "    global data, input_cnt, output_cnt \n",
    "    \n",
    "    input_cnt, output_cnt = 10, 1\n",
    "    data = np.zeros([len(rows), input_cnt + output_cnt])\n",
    "\n",
    "    for n, row in enumerate(rows):\n",
    "        if row[0] == 'M' : data[n, 0] = 1\n",
    "        if row[0] == 'F' : data[n, 1] = 1\n",
    "        if row[0] == 'I' : data[n, 2] = 1\n",
    "        data[n, 3 : ]= row[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e47bfb34-2f69-4023-999c-2d214d641ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run MathUtils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "82c12274-c501-4df8-9128-b8168c8cb149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.      0.      0.     ...  0.101   0.15   15.    ]\n",
      " [ 1.      0.      0.     ...  0.0485  0.07    7.    ]\n",
      " [ 0.      1.      0.     ...  0.1415  0.21    9.    ]\n",
      " ...\n",
      " [ 1.      0.      0.     ...  0.2875  0.308   9.    ]\n",
      " [ 0.      1.      0.     ...  0.261   0.296  10.    ]\n",
      " [ 1.      0.      0.     ...  0.3765  0.495  12.    ]]\n"
     ]
    }
   ],
   "source": [
    "load_dataset()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "16000aaf-f84a-454e-bea9-6080abe3942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_param():\n",
    "    global weight, bias\n",
    "    weight_initial = []\n",
    "    bias_initial = []\n",
    "    weight = np.random.normal(RND_MEAN, RND_STD, size = [input_cnt, output_cnt])\n",
    "    bias = np.zeros([output_cnt])\n",
    "    print(\"initial Weight Value: \\n{}\".format(weight))\n",
    "    print(\"initial Bias Value: \\n{}\".format(bias))\n",
    "    weight_initial.append(weight)\n",
    "    bias_initial.append(bias)\n",
    "    \n",
    "    return weight_initial, bias_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c7fe1993-6e80-41fa-8f47-be7859aa517a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial Weight Value: \n",
      "[[ 0.07865762]\n",
      " [-0.06150392]\n",
      " [-0.01501127]\n",
      " [ 0.00725753]\n",
      " [-0.01338488]\n",
      " [-0.02813899]\n",
      " [-0.0011171 ]\n",
      " [ 0.01609468]\n",
      " [ 0.02013071]\n",
      " [-0.0329204 ]]\n",
      "initial Bias Value: \n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "weight_initial, bias_initial = init_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dbe3bbb8-96fe-4ab9-823b-4a51fc8a29b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(epoch_count, mb_size, report, train_ratio):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4cb29f32-5f56-4176-afd9-2a46fd378c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4177, 11)\n"
     ]
    }
   ],
   "source": [
    "mb_size = 2\n",
    "train_ratio = 0.8\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "14ce0671-d069-4ccc-970f-1d6bb8ad6f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_data(mb_size, train_ratio):\n",
    "    \n",
    "    global shuffle_map, test_begin_index\n",
    "    \n",
    "    shuffle_map = np.arange(data.shape[0])\n",
    "    np.random.shuffle(shuffle_map)\n",
    "    \n",
    "    mini_batch_step_count = int(data.shape[0]*train_ratio) // mb_size\n",
    "    test_begin_index = mini_batch_step_count * mb_size\n",
    "    return mini_batch_step_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "95ab59ad-af62-4ee8-86e6-7851f8e9f74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini_batch_step_count: 1670\n",
      "shuffle_map :  [3885  921]\n",
      "test_begin_index :  3340\n"
     ]
    }
   ],
   "source": [
    "mini_batch_step_count = arrange_data(mb_size=2, train_ratio=0.8)\n",
    "print(\"mini_batch_step_count:\", mini_batch_step_count)\n",
    "print(\"shuffle_map : \",shuffle_map[:2])\n",
    "print(\"test_begin_index : \", test_begin_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b7efbb0b-134c-46ff-8353-685e970a20f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data():\n",
    "    test_data = data[shuffle_map[test_begin_index:]]\n",
    "    return test_data[:, : - output_cnt], test_data[:, -output_cnt: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9cc43f6a-2043-4ff2-b9a1-f38ba3fc26da",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.     1.     0.     ... 0.513  0.301  0.305 ]\n",
      " [0.     1.     0.     ... 0.7365 0.3055 0.37  ]\n",
      " [1.     0.     0.     ... 0.2405 0.127  0.139 ]\n",
      " ...\n",
      " [1.     0.     0.     ... 0.5785 0.3125 0.384 ]\n",
      " [1.     0.     0.     ... 0.4215 0.2255 0.227 ]\n",
      " [1.     0.     0.     ... 0.3495 0.2185 0.275 ]]\n",
      "===========================================\n",
      "[[10.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [14.]\n",
      " [13.]\n",
      " [13.]\n",
      " [ 7.]\n",
      " [10.]\n",
      " [16.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [ 7.]\n",
      " [11.]\n",
      " [ 6.]\n",
      " [12.]\n",
      " [ 9.]\n",
      " [21.]\n",
      " [14.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [12.]\n",
      " [15.]\n",
      " [10.]\n",
      " [ 7.]\n",
      " [10.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [11.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [14.]\n",
      " [15.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [13.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [12.]\n",
      " [ 6.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [11.]\n",
      " [13.]\n",
      " [11.]\n",
      " [10.]\n",
      " [12.]\n",
      " [10.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [11.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [12.]\n",
      " [ 7.]\n",
      " [13.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [12.]\n",
      " [10.]\n",
      " [14.]\n",
      " [10.]\n",
      " [16.]\n",
      " [11.]\n",
      " [10.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [14.]\n",
      " [11.]\n",
      " [11.]\n",
      " [11.]\n",
      " [11.]\n",
      " [15.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [ 6.]\n",
      " [12.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 9.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [12.]\n",
      " [ 8.]\n",
      " [18.]\n",
      " [ 8.]\n",
      " [18.]\n",
      " [11.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [18.]\n",
      " [10.]\n",
      " [13.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [10.]\n",
      " [12.]\n",
      " [ 6.]\n",
      " [12.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [15.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [11.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [15.]\n",
      " [14.]\n",
      " [ 9.]\n",
      " [ 7.]\n",
      " [11.]\n",
      " [13.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [14.]\n",
      " [ 6.]\n",
      " [11.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [10.]\n",
      " [ 6.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [12.]\n",
      " [10.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [12.]\n",
      " [ 7.]\n",
      " [12.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [13.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [13.]\n",
      " [ 7.]\n",
      " [12.]\n",
      " [12.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [ 7.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [13.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 6.]\n",
      " [ 9.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [16.]\n",
      " [ 6.]\n",
      " [13.]\n",
      " [ 8.]\n",
      " [13.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [11.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [14.]\n",
      " [13.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [10.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 9.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [15.]\n",
      " [ 7.]\n",
      " [10.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [11.]\n",
      " [11.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [ 7.]\n",
      " [11.]\n",
      " [17.]\n",
      " [11.]\n",
      " [15.]\n",
      " [15.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [11.]\n",
      " [11.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [15.]\n",
      " [11.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [21.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [15.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [17.]\n",
      " [10.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [ 7.]\n",
      " [12.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [11.]\n",
      " [12.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [12.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [ 7.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [13.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [12.]\n",
      " [14.]\n",
      " [ 7.]\n",
      " [11.]\n",
      " [15.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [ 6.]\n",
      " [15.]\n",
      " [11.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [11.]\n",
      " [10.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [15.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [14.]\n",
      " [10.]\n",
      " [10.]\n",
      " [13.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [11.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [ 6.]\n",
      " [10.]\n",
      " [ 6.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [14.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [12.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [16.]\n",
      " [13.]\n",
      " [12.]\n",
      " [14.]\n",
      " [ 7.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [10.]\n",
      " [12.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [12.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [12.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [10.]\n",
      " [ 4.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [12.]\n",
      " [13.]\n",
      " [11.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [13.]\n",
      " [ 6.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [11.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [13.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [14.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [13.]\n",
      " [ 7.]\n",
      " [13.]\n",
      " [11.]\n",
      " [10.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [10.]\n",
      " [17.]\n",
      " [10.]\n",
      " [14.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [12.]\n",
      " [ 9.]\n",
      " [23.]\n",
      " [10.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [13.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [12.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [23.]\n",
      " [14.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [10.]\n",
      " [13.]\n",
      " [ 6.]\n",
      " [12.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [12.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [14.]\n",
      " [11.]\n",
      " [11.]\n",
      " [13.]\n",
      " [10.]\n",
      " [12.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [13.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [10.]\n",
      " [13.]\n",
      " [11.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [13.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [12.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [ 6.]\n",
      " [14.]\n",
      " [ 6.]\n",
      " [ 9.]\n",
      " [18.]\n",
      " [14.]\n",
      " [ 9.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [12.]\n",
      " [ 6.]\n",
      " [11.]\n",
      " [12.]\n",
      " [13.]\n",
      " [12.]\n",
      " [14.]\n",
      " [11.]\n",
      " [19.]\n",
      " [20.]\n",
      " [11.]\n",
      " [17.]\n",
      " [11.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [11.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [11.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [19.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [10.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [10.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [19.]\n",
      " [10.]\n",
      " [ 6.]\n",
      " [12.]\n",
      " [14.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [ 8.]\n",
      " [ 3.]\n",
      " [ 9.]\n",
      " [12.]\n",
      " [ 7.]\n",
      " [20.]\n",
      " [14.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [12.]\n",
      " [12.]\n",
      " [12.]\n",
      " [10.]\n",
      " [ 7.]\n",
      " [14.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 4.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [14.]\n",
      " [11.]\n",
      " [ 5.]\n",
      " [15.]\n",
      " [15.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [10.]\n",
      " [12.]\n",
      " [11.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [13.]\n",
      " [ 8.]\n",
      " [11.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [11.]\n",
      " [17.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [17.]\n",
      " [ 9.]\n",
      " [12.]\n",
      " [10.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [17.]\n",
      " [ 8.]\n",
      " [12.]\n",
      " [12.]\n",
      " [10.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [12.]\n",
      " [13.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [13.]\n",
      " [12.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [11.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [12.]\n",
      " [ 4.]\n",
      " [14.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [13.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [11.]\n",
      " [13.]\n",
      " [11.]\n",
      " [11.]\n",
      " [10.]\n",
      " [13.]\n",
      " [ 7.]\n",
      " [13.]\n",
      " [ 7.]\n",
      " [10.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [12.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [ 6.]\n",
      " [12.]\n",
      " [20.]\n",
      " [15.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [11.]\n",
      " [12.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [15.]\n",
      " [12.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [ 6.]\n",
      " [12.]\n",
      " [11.]\n",
      " [15.]\n",
      " [ 8.]\n",
      " [12.]\n",
      " [11.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [20.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [16.]\n",
      " [ 8.]\n",
      " [16.]\n",
      " [16.]\n",
      " [ 8.]\n",
      " [17.]\n",
      " [ 6.]\n",
      " [10.]\n",
      " [10.]\n",
      " [12.]\n",
      " [10.]\n",
      " [11.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [16.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [15.]\n",
      " [ 9.]\n",
      " [13.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [10.]\n",
      " [13.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 9.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [15.]\n",
      " [21.]\n",
      " [10.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [11.]\n",
      " [11.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [11.]\n",
      " [12.]\n",
      " [ 7.]\n",
      " [16.]\n",
      " [11.]\n",
      " [14.]\n",
      " [13.]\n",
      " [ 8.]\n",
      " [14.]\n",
      " [11.]\n",
      " [12.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [13.]\n",
      " [11.]\n",
      " [ 4.]\n",
      " [12.]\n",
      " [12.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [10.]\n",
      " [11.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [14.]\n",
      " [10.]\n",
      " [23.]\n",
      " [10.]\n",
      " [ 9.]\n",
      " [17.]]\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y = get_test_data()\n",
    "print(test_x)\n",
    "print(\"===========================================\")\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7a3e7dd1-4590-427d-baba-0d76e7fb6f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(mb_size, n):\n",
    "    if n == 0:\n",
    "        np.random.shuffle(shuffle_map[:test_begin_index])\n",
    "        \n",
    "    train_data = data[shuffle_map[mb_size * n : mb_size*(n+1)]]\n",
    "    \n",
    "    return train_data[:, :-output_cnt], train_data[:, -output_cnt :]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e12edab6-b637-4d0a-87bf-708105795995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.     1.     0.     0.515  0.375  0.11   0.6065 0.3005 0.131  0.15  ]\n",
      " [0.     0.     1.     0.285  0.205  0.07   0.106  0.039  0.0285 0.034 ]]\n",
      "=============================\n",
      "[[6.]\n",
      " [5.]]\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = get_train_data(mb_size = 2, n = 0)\n",
    "print(train_x)\n",
    "print(\"=============================\")\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "093c77c3-64d4-4b21-b127-9c2e094d74f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_test(x, y):\n",
    "    accuracy = 100\n",
    "    return accuracy\n",
    "run_test(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ba53857c-7f68-47e4-b06a-ea83269c0991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 95)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_train(x, y):\n",
    "    loss = 0\n",
    "    accuracy = 95\n",
    "    return loss, accuracy\n",
    "run_train(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "72e0ee06-61ea-4dee-8fd9-82432d28be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(epoch_count, mb_size, report, train_ratio):\n",
    "    mini_batch_step_count = arrange_data(mb_size, train_ratio)\n",
    "    test_x, test_y = get_test_data()\n",
    "    \n",
    "    losses_mean_row = []\n",
    "    accs_mean_row = []\n",
    "    \n",
    "    for epoch in range(epoch_count):\n",
    "        losses = []\n",
    "        accs = []\n",
    "        for n in range(mini_batch_step_count):\n",
    "            train_x, train_y = get_train_data(mb_size, n)\n",
    "            loss, acc = run_train(train_x, train_y)\n",
    "            losses.append(loss)\n",
    "            accs.append(acc)\n",
    "            \n",
    "        if report >0 and (epoch +1)% report == 0:\n",
    "            acc = run_test(test_x, test_y)\n",
    "            print(\"Epoch {} : Train - Loss = {:.3f}, Accuracy = {:.3f}  / Test - Accuracy = {:.3f}\".\\\n",
    "                  format(epoch + 1, np.mean(losses), np.mean(accs), acc))\n",
    "            \n",
    "        losses_mean = np.mean(losses)\n",
    "        accs_mean = np.mean(accs)*100\n",
    "        \n",
    "    final_acc = run_test(test_x, test_y)\n",
    "    print(\"=\" * 30, \"Final TEST\", \"=\" * 30)\n",
    "    print(\"\\nFinal Accuracy : {:.3f}\".format(final_acc))\n",
    "    \n",
    "    return losses_mean, accs_mean, final_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "be0215a4-689d-4411-b8b5-1c63b2a24bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 : Train - Loss = 0.000, Accuracy = 95.000  / Test - Accuracy = 100.000\n",
      "Epoch 6 : Train - Loss = 0.000, Accuracy = 95.000  / Test - Accuracy = 100.000\n",
      "Epoch 9 : Train - Loss = 0.000, Accuracy = 95.000  / Test - Accuracy = 100.000\n",
      "============================== Final TEST ==============================\n",
      "\n",
      "Final Accuracy : 100.000\n"
     ]
    }
   ],
   "source": [
    "result = train_and_test(epoch_count=10, mb_size=2, report = 3, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9eacea4c-6aeb-47a5-aaba-e3ca2426b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_neuralnet(x):\n",
    "    y_hat = np.matmul(x, weight) + bias\n",
    "    return y_hat, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "12ef2088-0732-434e-8d03-cc891f575b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat : \n",
      " [[-0.06402292]\n",
      " [-0.01769279]]\n",
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "y_hat, _ = forward_neuralnet(train_x)\n",
    "print(\"y_hat : \\n\", y_hat)\n",
    "print(y_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0d390ba7-74d8-4a54-a30c-d2ff749f7876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_postproc(y_hat, y):\n",
    "    diff = y_hat - y\n",
    "    square = np.square(diff)\n",
    "    loss = np.mean(square)\n",
    "    \n",
    "    return loss, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cba02bcc-28b6-47d6-83a9-9252ef444023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3fcaf050-0f10-4be8-aa39-db18e85910e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.97480745361902\n"
     ]
    }
   ],
   "source": [
    "loss, _ = forward_postproc(y_hat, train_y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c6197b4b-9c60-4a83-a0ad-f9ca2acf4c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가\n",
    "def eval_accuracy(y_hat, y):\n",
    "    mdiff = np.mean(np.abs((y_hat-y) / y))\n",
    "    return 1 - mdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cedb3d64-908c-4596-ade8-aa4089b42a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc : -0.71\n"
     ]
    }
   ],
   "source": [
    "acc = eval_accuracy(y_hat, train_y)\n",
    "print(\"Acc : {}\".format(np.round(acc*100,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f655c5-7f21-4b90-b440-7af606707e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
